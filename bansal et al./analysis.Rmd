---
title: "analysis for Bansal et al."
output:
  pdf_document: default
  html_document: default
date: "2023-12-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(RJSONIO)
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggdist)
library(brms)
library(vmc)
library(tidybayes)
library(cowplot)
```

In this document, we run the reliance framework analysis for LSAT task and its corresponding explanations in Bansal et al. We estimate the behavioral agents' joint behavioral $\pi(\theta, v, a^b)$ by a statistical model fitted on the experiment data. We first show the results using approximation of rational benchmark and the mis-reliant rational benchmark with overfitting to the empirical distribution and then show the results using approximation with the discretized signals generated by the K-Means model.

```{r}
task_name = "lsat"  # "lsat" | "beer" | "amzbook"
bonus =1 # 0.3  # 0.3 | 0.05
```

```{r read raw data}
raw_data = read.csv("decision-result-filter.csv") %>% filter(task == task_name)
```

```{r analysis}
choice_plot = raw_data %>% 
  ggplot() + 
  geom_bar(aes(x = choice)) + 
  facet_wrap(vars(condition))

y_plot = raw_data %>% 
  ggplot() + 
  geom_bar(aes(x = y)) + 
  facet_wrap(vars(condition))
plot_grid(choice_plot, y_plot)
```

```{r prior choice model}
prior.choice <- brm(data = raw_data, family = "categorical",
                      bf(choice ~ 1),
                      sample_prior = "only",
                      iter = 3000, warmup = 500, chains = 4, cores = 4)
```

```{r check prior choice model}
pred = raw_data %>%
  add_predicted_draws(prior.choice, ndraws = 50)
obs_plot = pred %>% ggplot(aes(x = choice)) + geom_bar()
model_plot = pred %>% ggplot(aes(x = .prediction)) + geom_bar()
plot_grid(obs_plot, model_plot)
```

```{r choice model}
m.choice = brm(data = raw_data, family = "categorical",
                      bf(choice ~ 1),
                      iter = 3000, warmup = 500, chains = 4, cores = 4,
               file = "./models/m_choice_mdl")
```

```{r check choice model}
pred = raw_data %>%
  add_predicted_draws(m.choice, ndraws = 50)
obs_plot = pred %>% ggplot(aes(x = choice)) + geom_bar()
model_plot = pred %>% ggplot(aes(x = .prediction)) + geom_bar()
plot_grid(obs_plot, model_plot)
```

```{r check facet choice model}
pred = raw_data %>%
  add_predicted_draws(m.choice, ndraws = 50)
obs_plot = pred %>% ggplot(aes(x = choice)) + geom_bar() + facet_wrap(vars(questionId))
model_plot = pred %>% ggplot(aes(x = .prediction)) + geom_bar() + facet_wrap(vars(questionId))
plot_grid(obs_plot, model_plot)
```


```{r choice y model}
m.choice_y = brm(data = raw_data, family = "categorical",
                      bf(choice ~ y),
                      iter = 3000, warmup = 500, chains = 4, cores = 4)
```

```{r check choice y model}
pred = raw_data %>%
  add_predicted_draws(m.choice_y, ndraws = 50)
obs_plot = pred %>% ggplot(aes(x = choice)) + geom_bar() + facet_wrap(vars(questionId))
model_plot = pred %>% ggplot(aes(x = .prediction)) + geom_bar() + facet_wrap(vars(questionId))
plot_grid(obs_plot, model_plot)
```


```{r choice y condition model}
m.choice_y_condition = brm(data = raw_data, family = "categorical",
                      bf(choice ~ y + condition),
                      iter = 3000, warmup = 500, chains = 4, cores = 4,
                      file = "./models/m_choice_y_condition_mdl")
```

```{r check choice y condition model}
pred = raw_data %>%
  add_predicted_draws(m.choice_y_condition, ndraws = 50)
obs_plot = pred %>% ggplot(aes(x = choice)) + geom_bar() + facet_wrap(vars(questionId))
model_plot = pred %>% ggplot(aes(x = .prediction)) + geom_bar() + facet_wrap(vars(questionId))
plot_grid(obs_plot, model_plot)
```

```{r choice y condition interaction model}
m.choice_y_condition_interaction = brm(data = raw_data, family = "categorical",
                      bf(choice ~ y * condition),
                      iter = 3000, warmup = 500, chains = 4, cores = 4,
                      file = "./models/m_choice_y_condition_interaction_mdl")
```

```{r check choice y condition interaction model}
pred = raw_data %>%
  add_predicted_draws(m.choice_y_condition_interaction, ndraws = 50)
obs_plot = pred %>% ggplot(aes(x = choice)) + geom_bar() + facet_wrap(vars(questionId))
model_plot = pred %>% ggplot(aes(x = .prediction)) + geom_bar() + facet_wrap(vars(questionId))
plot_grid(obs_plot, model_plot)
```

```{r choice y condition random effect model}
m.choice_y_condition_re = brm(data = raw_data, family = "categorical",
                      bf(choice ~ y * condition + (1 | assignmentId)),
                      iter = 3000, warmup = 500, chains = 4, cores = 4,
                      file = "./models/m_choice_y_condition_re_mdl")
```

```{r check choice y condition re model}
pred = raw_data %>%
  add_predicted_draws(m.choice_y_condition_re, ndraws = 50)
obs_plot = pred %>% ggplot(aes(x = choice)) + geom_bar() + facet_wrap(vars(questionId))
model_plot = pred %>% ggplot(aes(x = .prediction)) + geom_bar() + facet_wrap(vars(questionId))
plot_grid(obs_plot, model_plot)
```

```{r choice y condition pred random effect model}
m.choice_y_condition_pred_re = brm(data = raw_data, family = "categorical",
                      bf(choice ~ y * condition + pred + pred2 + (1 | assignmentId)),
                      iter = 3000, warmup = 500, chains = 4, cores = 4,
                      file = "./models/m_choice_y_condition_pred_re_mdl")
```


```{r check choice y condition pred re model}
pred = raw_data %>%
  add_predicted_draws(m.choice_y_condition_pred_re, ndraws = 50)
obs_plot = pred %>% ggplot(aes(x = choice)) + geom_bar() + facet_wrap(vars(questionId))
model_plot = pred %>% ggplot(aes(x = .prediction)) + geom_bar() + facet_wrap(vars(questionId))
plot_grid(obs_plot, model_plot)
```


```{r check choice y condition pred re model on condition}
pred = raw_data %>%
  add_predicted_draws(m.choice_y_condition_pred_re, ndraws = 50)
obs_plot = pred %>% ggplot(aes(x = choice)) + geom_bar() + facet_wrap(vars(condition))
model_plot = pred %>% ggplot(aes(x = .prediction)) + geom_bar() + facet_wrap(vars(condition))
plot_grid(obs_plot, model_plot)
```

```{r read data}
meta_data = raw_data %>% group_by(questionId, condition, y, pred, conf, conf2, pred2) %>% summarise()
pred_human_data = meta_data %>% 
  filter(condition == "Human") %>% 
  add_predicted_draws(m.choice_y_condition_pred_re, ndraws = 1000, re_formula = NA)
human_predictions = pred_human_data %>% 
  rename(human_pred = .prediction) %>%
  ungroup() %>%
  select(-condition, -.row, -.chain, -.iteration)
exp_data = meta_data %>% 
  filter(condition != "Human") %>% 
  left_join(human_predictions, 
            by = join_by(questionId, y, pred, conf, conf2, pred2)) %>%
  rename(drawId = .draw) %>%
  add_predicted_draws(m.choice_y_condition_pred_re, ndraws = 1, re_formula = NA) %>%
  rename(choice = .prediction, drawId2 = .draw) %>%
  ungroup() %>%
  select(-.row, -.chain, -.iteration)
```


```{r read task data}
con <- file('./task-lsat.json', "r")
task_data <- ldply(fromJSON(con), data.frame)
task_data = task_data[!duplicated(task_data$id), ]
task_data = task_data %>% 
  unite("text_signal", choices.A:question, remove = FALSE)
```


```{r scoring rules}
payoff = function(action, state) {
  (action == state) * bonus
}
expected_payoff = function(action, states) {
  return(mean((action == states) * bonus))
}
mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```

```{r nlp and kmeans}
corpus = tm::Corpus(tm::VectorSource(task_data$text_signal)) 
corpus.cleaned <- tm::tm_map(corpus, tm::removeWords, tm::stopwords('english')) # Removing stop-words 
corpus.cleaned <- tm::tm_map(corpus, tm::stemDocument, language = "english") # Stemming the words  
corpus.cleaned <- tm::tm_map(corpus.cleaned, tm::stripWhitespace) # Trimming excessive whitespaces
tdm <- tm::DocumentTermMatrix(corpus.cleaned) 
tdm.tfidf <- tm::weightTfIdf(tdm)
tdm.tfidf <- tm::removeSparseTerms(tdm.tfidf, 0.999) 
tfidf.matrix <- as.matrix(tdm.tfidf) 
```

```{r cross validation to choose best K in kmeans}
predict.kmeans <- function(object, newdata){
  centers <- object$centers
  n_centers <- nrow(centers)
  dist_mat <- as.matrix(dist(rbind(centers, newdata)))
  dist_mat <- dist_mat[-seq(n_centers), seq(n_centers)]
  list(cluster = max.col(-dist_mat), total_error = sum(apply(dist_mat, 1, function(x) min(x))))
}

number_of_partition = 10
partition_size = nrow(tfidf.matrix) / number_of_partition
best.K = -1
best.test_sd = Inf
best.benchmark = c()
for (K in (2:17)) {
  benchmark = c()
  for (i in seq(1, nrow(tfidf.matrix), partition_size)) {
    test_set = tfidf.matrix[i:(i + partition_size - 1),]
    training_set = tfidf.matrix[-(i:(i + partition_size - 1)),]
    clustering.kmeans <- kmeans(training_set, K)
    cluster_number = predict(clustering.kmeans, test_set)$cluster
    test_questionId = task_data$id[i:(i + partition_size - 1)]
    
    test_task_data = task_data %>% filter(id %in% test_questionId) %>% mutate(cluster = cluster_number)
    test_human_predictions = human_predictions %>% 
      filter(questionId %in% test_questionId) %>%
      left_join(test_task_data %>% select(questionId = id, cluster), by = c("questionId"))
    
    train_task_data = task_data %>% filter(!(id %in% test_questionId)) %>% mutate(cluster = clustering.kmeans$cluster)
    train_human_predictions = human_predictions %>% 
      filter(!(questionId %in% test_questionId)) %>%
      left_join(train_task_data %>% select(questionId = id, cluster), by = c("questionId"))
    
    test_rational_action = train_human_predictions %>%
      rbind(test_human_predictions) %>%
      mutate(human_pred = as.character(human_pred)) %>%
      group_by(human_pred, pred, pred2, cluster) %>%
      mutate(human_payoff = payoff(human_pred, y),
                pred_payoff = payoff(pred, y),
                pred2_payoff = payoff(pred2, y)) %>%
      summarise(human_payoff = mean(human_payoff),
                pred_payoff = mean(pred_payoff),
                pred2_payoff = mean(pred2_payoff))
    benchmark = c(benchmark, (test_human_predictions %>%
      left_join(test_rational_action, by = c("pred", "pred2", "human_pred", "cluster")) %>%
      mutate(pred_better = ifelse(pred_payoff >= pred2_payoff, pred, pred2),
             pred_better_payoff = ifelse(pred_payoff >= pred2_payoff, pred_payoff, pred2_payoff)) %>%
      mutate(rational_benchmark_action = ifelse(pred_better_payoff > human_payoff, pred_better, human_pred)) %>%
      mutate(rational_benchmark = (rational_benchmark_action == y) * bonus) %>%
      summarise(rational_benchmark = mean(rational_benchmark)))$rational_benchmark)
  }
  if (best.test_sd > sd(benchmark)) {
    best.test_sd = sd(benchmark)
    best.benchmark = benchmark
    best.K = K
  }
}
best.K
```

```{r kmeans}
clustering.kmeans <- kmeans(tfidf.matrix, best.K)
```

```{r mutate cluster number}
task_data = task_data %>% mutate(cluster = clustering.kmeans$cluster)
exp_data = exp_data %>% left_join(task_data %>% select(questionId = id, cluster))
human_predictions = human_predictions %>% left_join(task_data %>% select(questionId = id, cluster))
```




```{r rational prior action}
rational_prior_action = ifelse(expected_payoff(human_predictions$human_pred, human_predictions$y) > 
                                 max(expected_payoff(human_predictions$pred, human_predictions$y),                                                           expected_payoff(human_predictions$pred2, human_predictions$y)),
                               "human", "pred")
rational_prior_action
```

## Approximating by overfitting to the empirical distribution

```{r calculate quantities}
rational_action = human_predictions %>% 
  mutate(human_pred = as.character(human_pred)) %>%
  group_by(human_pred, pred, pred2, questionId) %>%
  mutate(human_payoff = payoff(human_pred, y),
            pred_payoff = payoff(pred, y),
            pred2_payoff = payoff(pred2, y)) %>%
  summarise(human_payoff = mean(human_payoff),
            pred_payoff = mean(pred_payoff),
            pred2_payoff = mean(pred2_payoff))
exp_data_with_reliance = exp_data %>%
  mutate(human_pred = as.character(human_pred)) %>%
  mutate(choice = as.character(choice)) %>%
  mutate(behavioral_payoff = (choice == y) * bonus) %>%
  left_join(rational_action) %>%
  # mutate(pred_better = pred,
  #        pred_better_payoff = pred_payoff) %>%
  mutate(pred_better = ifelse(pred_payoff >= pred2_payoff, pred, pred2),
         pred_better_payoff = ifelse(pred_payoff >= pred2_payoff, pred_payoff, pred2_payoff)) %>%
  group_by(drawId, drawId2, condition) %>%
  arrange(desc(pred_better_payoff - human_payoff), .by_group = TRUE) %>%
  mutate(sort_id = row_number()) %>%
  mutate(is_relying = ((choice == pred) | (choice == pred2)) & (choice != human_pred)) %>%
  mutate(reliance = sum(is_relying)) %>%
  ungroup() %>%
  mutate(action = ifelse(sort_id <= reliance,
                         pred_better, 
                         human_pred)) %>%
  mutate(misreliant_payoff = (action == y) * bonus) %>%
  mutate(rational_benchmark_action = ifelse(pred_better_payoff > human_payoff, pred_better, human_pred)) %>%
  mutate(rational_benchmark = (rational_benchmark_action == y) * bonus) %>%
  mutate(rational_rl = ((rational_benchmark_action == pred) | 
                                  (rational_benchmark_action == pred2)) & 
           (rational_benchmark_action != human_pred)) %>%
  rowwise() %>%
  mutate(rational_baseline_action = pred) %>%
  mutate(rational_baseline = (rational_baseline_action == y) * bonus) %>%
  mutate(rational_baseline2_action = human_pred) %>%
  mutate(rational_baseline2 = (rational_baseline2_action == y) * bonus)
```

```{r calibrated}
calibrated_human_actions = human_predictions %>%
  group_by(human_pred) %>%
  summarise(calibrated_human_action = mode(y))
calibrated_ai_actions = human_predictions %>%
  group_by(pred) %>%
  summarise(calibrated_ai_action = mode(y))
calibrated_rational_actions = human_predictions %>%
  group_by(pred, human_pred) %>%
  summarise(calibrated_rational_action = mode(y))
calibrated_prior_actions = human_predictions %>%
  ungroup() %>%
  summarise(calibrated_prior_action = mode(y))
calibrated_data = human_predictions %>%
  left_join(calibrated_human_actions) %>%
  left_join(calibrated_ai_actions) %>%
  left_join(calibrated_rational_actions) %>%
  cross_join(calibrated_prior_actions) %>%
  mutate(calibrated_human_payoff = payoff(calibrated_human_action, y),
         calibrated_AI_payoff = payoff(calibrated_ai_action, y),
         calibrated_rational_payoff = payoff(calibrated_rational_action, y),
         prior_rational_payoff = payoff(calibrated_prior_action, y),
         human_payoff = payoff(human_pred, y),
         ai_payoff = payoff(pred, y))

sample_size = 200
n_round = 500
calibrated_results = data.frame()
for (i in 1:n_round) {
  calibrated_results = calibrated_data %>% 
    sample_n(sample_size) %>%
    ungroup() %>%
    summarise(benchmark = mean(calibrated_rational_payoff), 
              baseline = mean(prior_rational_payoff),
              calibrated_human = mean(calibrated_human_payoff), 
              calibrated_ai = mean(calibrated_AI_payoff),
              human_payoff = mean(human_payoff),
              ai_payoff = mean(ai_payoff)) %>%
    rbind(calibrated_results)
}
calibrated_results

colors <- c("Benchmark" = "#1F2041", "calibrated_human" = "#fc8d62", "calibrated_ai" = "#8da0cb", "human" = "green", "Baseline" = "blue", "ai" = "green") 
ggplot() +
  stat_slabinterval(data = calibrated_results, aes(x = calibrated_human, fill = "calibrated_human"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = calibrated_results, aes(x = calibrated_ai, fill = "calibrated_ai"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = calibrated_results, aes(x = benchmark, fill = "Benchmark"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = calibrated_results, aes(x = human_payoff, fill = "human"), alpha = .8, color = "#202020", size = 3) +
  # stat_slabinterval(data = calibrated_results, aes(y = setting, x = ai_payoff, fill = "ai"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = calibrated_results, aes(x = baseline, fill = "Baseline"), alpha = .8, color = "#202020", size = 3) +
  labs(x = "", y = "", color = "Quantiy") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.major = element_line(colour = "grey"),
        axis.line.x = element_line(linewidth = 1.5, colour = "grey80"),
        panel.background = element_rect(fill = "white", color = "white"),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_line(colour = "grey")) + 
  scale_fill_manual(values = colors)
```

```{r bootstrap}
sample_size = 100 * 20
n_round = 500
results = data.frame()
for (i in 1:n_round) {
  results = exp_data_with_reliance %>% 
    group_by(condition) %>%
    sample_n(sample_size) %>%
    # group_by(condition) %>%
    summarise(behavioral_payoff = mean(behavioral_payoff), 
              misreliant_payoff = mean(misreliant_payoff),
              benchmark_payoff = mean(rational_benchmark),
              baseline_payoff = mean(rational_baseline),
              baseline2_payoff = mean(rational_baseline2),
              reliance = mean(reliance),
              rational_reliance = mean(rational_rl)) %>%
    rbind(results)
}
results
```



```{r visualization}
colors <- c("Baseline" = "#a6d854", "Baseline(human alone)" = "#e78ac3", "Benchmark" = "#1F2041", "Behavioral" = "#fc8d62", "Misreliant" = "#8da0cb")
ggplot() +
  stat_slabinterval(data = results, aes(y = condition, x = behavioral_payoff, fill = "Behavioral"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = results, aes(y = condition, x = misreliant_payoff, fill = "Misreliant"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = results, aes(y = condition, x = baseline2_payoff, fill = "Baseline(human alone)"), alpha = .8, color = "#202020", size = 2) +
  stat_slabinterval(data = results, aes(y = condition, x = baseline_payoff, fill = "Baseline"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = results, aes(y = condition, x = benchmark_payoff, fill = "Benchmark"), alpha = .8, color = "#202020", size = 3) +
  # geom_vline(xintercept = as.vector(rational_benchmark)$expected_payoff, linetype = "dashed", size = 1) +
  # geom_vline(data = results, aes(xintercept = baseline_payoff, linetype = "Baseline"), size = 1) +
  labs(x = "", y = "") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.major = element_line(colour = "grey"),
        axis.line.x = element_line(linewidth = 1.5, colour = "grey80"),
        panel.background = element_rect(fill = "white", color = "white"),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_line(colour = "grey")) + 
  scale_fill_manual(values = colors)
# ggsave("./bansal_results.pdf", unit = "in", width = 7.22222222222, height = 3.47222222222)
```

```{r reliance plot}
quantile_data = exp_data_with_reliance %>%
  group_by(questionId) %>%
  summarise(EAIhuman = mean(pred_better_payoff - human_payoff)) %>%
  arrange(desc(EAIhuman)) %>%
  mutate(sortId = row_number())
quantile_data = quantile_data %>%
  mutate(quantile = sortId / nrow(quantile_data)) %>%
  mutate(cum_EAIhuman = cumsum(EAIhuman))
reliance_data = exp_data_with_reliance %>% 
   group_by(drawId, condition) %>% 
   summarise(reliance = mean(is_relying))

p1 = quantile_data %>%
  ggplot() +
  geom_line(aes(x = quantile, y = EAIhuman)) +
  geom_hline(yintercept = 0) +
  labs(x = "The Quantile of signals", y = "", color = '') +
  xlim(0, 1) +
  theme_light()
p2 = reliance_data %>%
  ggplot() +
  stat_pointinterval(aes(x = reliance, y = condition, color = condition), point_size = 2) +
  xlim(0, 1) +
  theme_light() +
  theme(legend.position = "none") +
  scale_y_discrete(labels = c(-0.5,0.0,0.5,0.5)) +
  labs(x = "Reliance levels", y = "", color = '')
plot_grid(p1, p2, cols = 1)
ggsave("./bansal_reliance.pdf", unit = "in", width = 7.22222222222 * 0.9, height = 3.47222222222 * 1.8)
```

# Using discretized signals to approximate

```{r discretized signals}
rational_action = human_predictions %>% 
  mutate(human_pred = as.character(human_pred)) %>%
  group_by(human_pred, pred, pred2, cluster) %>%
  mutate(human_payoff = payoff(human_pred, y),
            pred_payoff = payoff(pred, y),
            pred2_payoff = payoff(pred2, y)) %>%
  summarise(human_payoff = mean(human_payoff),
            pred_payoff = mean(pred_payoff),
            pred2_payoff = mean(pred2_payoff))
exp_data_with_reliance = exp_data %>%
  mutate(human_pred = as.character(human_pred)) %>%
  mutate(choice = as.character(choice)) %>%
  mutate(behavioral_payoff = (choice == y) * bonus) %>%
  left_join(rational_action) %>%
  # mutate(pred_better = pred,
  #        pred_better_payoff = pred_payoff) %>%
  mutate(pred_better = ifelse(pred_payoff >= pred2_payoff, pred, pred2),
         pred_better_payoff = ifelse(pred_payoff >= pred2_payoff, pred_payoff, pred2_payoff)) %>%
  group_by(drawId, drawId2, condition) %>%
  arrange(desc(pred_better_payoff - human_payoff), .by_group = TRUE) %>%
  mutate(sort_id = row_number()) %>%
  mutate(is_relying = ((choice == pred) | (choice == pred2)) & (choice != human_pred)) %>%
  mutate(reliance = sum(is_relying)) %>%
  ungroup() %>%
  mutate(action = ifelse(sort_id <= reliance,
                         pred_better, 
                         human_pred)) %>%
  mutate(misreliant_payoff = (action == y) * bonus) %>%
  mutate(rational_benchmark_action = ifelse(pred_better_payoff > human_payoff, pred_better, human_pred)) %>%
  mutate(rational_benchmark = (rational_benchmark_action == y) * bonus) %>%
  mutate(rational_rl = ((rational_benchmark_action == pred) | 
                                  (rational_benchmark_action == pred2)) & 
           (rational_benchmark_action != human_pred)) %>%
  rowwise() %>%
  mutate(rational_baseline_action = pred) %>%
  mutate(rational_baseline = (rational_baseline_action == y) * bonus) %>%
  mutate(rational_baseline2_action = human_pred) %>%
  mutate(rational_baseline2 = (rational_baseline2_action == y) * bonus)

sample_size = 100 * 20
n_round = 500
results = data.frame()
for (i in 1:n_round) {
  results = exp_data_with_reliance %>% 
    group_by(condition) %>%
    sample_n(sample_size) %>%
    # group_by(condition) %>%
    summarise(behavioral_payoff = mean(behavioral_payoff), 
              misreliant_payoff = mean(misreliant_payoff),
              benchmark_payoff = mean(rational_benchmark),
              baseline_payoff = mean(rational_baseline),
              baseline2_payoff = mean(rational_baseline2),
              reliance = mean(reliance),
              rational_reliance = mean(rational_rl)) %>%
    rbind(results)
}

ggplot() +
  stat_slabinterval(data = results, aes(y = condition, x = behavioral_payoff, fill = "Behavioral"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = results, aes(y = condition, x = misreliant_payoff, fill = "Misreliant"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = results, aes(y = condition, x = baseline2_payoff, fill = "Baseline(human alone)"), alpha = .8, color = "#202020", size = 2) +
  stat_slabinterval(data = results, aes(y = condition, x = baseline_payoff, fill = "Baseline"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = results, aes(y = condition, x = benchmark_payoff, fill = "Benchmark"), alpha = .8, color = "#202020", size = 3) +
  # geom_vline(xintercept = as.vector(rational_benchmark)$expected_payoff, linetype = "dashed", size = 1) +
  # geom_vline(data = results, aes(xintercept = baseline_payoff, linetype = "Baseline"), size = 1) +
  labs(x = "", y = "") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.major = element_line(colour = "grey"),
        axis.line.x = element_line(linewidth = 1.5, colour = "grey80"),
        panel.background = element_rect(fill = "white", color = "white"),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_line(colour = "grey")) + 
  scale_fill_manual(values = colors)
# ggsave("./bansal_results_test_performance.pdf", unit = "in", width = 7.22222222222, height = 3.47222222222)
```



