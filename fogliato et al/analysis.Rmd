---
title: "analysis for fogliato et al."
output:
  pdf_document: default
  html_document: default
date: "2023-12-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(ggdist)
library(cowplot)
```

In this document, we run the reliance framework analysis for recidivism decision task and the corresponding conditions in Fogliato et al. We estimate the behavioral agents' joint behavioral $\pi(\theta, v, a^b)$ by the empirical distribution in the experiment data. We first show the results using approximation of rational benchmark and the mis-reliant rational benchmark with overfitting to the empirical distribution and then show the results using approximation with the discretized signals generated by the binned confidence score by the AI model.

```{r read data}
raw_data = read.csv("Predictions.csv")
human_predictions = raw_data %>% filter(survey_part == 1)
exp_data = raw_data %>% filter(survey_part == 2)
exp_data = exp_data %>% 
  left_join(human_predictions %>% 
              select(index, human_pred = qb_h, human_pred_p = qp_h)) %>% 
  # mutate(qb_h = ifelse(is.na(qb_h), human_pred, qb_h), 
  #        qp_h = ifelse(is.na(qp_h), human_pred_p, qp_h)) %>% 
  mutate(qb_h = human_pred, 
         qp_h = human_pred_p) %>%
  select(-human_pred, -human_pred_p)
```

```{r scoring rule}
scoring_rule = function(action, state) {
  1 - (action - state) * (action - state)
}
```

## Approximating by overfitting to the empirical distribution

```{r rational baseline}
rational_data = human_predictions %>% 
  mutate(prior_human_payoff = mean(scoring_rule(qb_h, outcome)),
         prior_ai_payoff = mean(scoring_rule(qb_r, outcome))) %>%
  mutate(baseline_action = ifelse(prior_human_payoff > prior_ai_payoff, qb_h, qb_r)) %>%
  mutate(baseline = scoring_rule(baseline_action, outcome)) %>%
  mutate(baseline2_action = ifelse(prior_human_payoff <= prior_ai_payoff, qb_h, qb_r)) %>%
  mutate(baseline2 = scoring_rule(baseline2_action, outcome))

rational_data_p = human_predictions %>% 
  mutate(prior_human_payoff_p = mean(scoring_rule(qp_h, outcome)),
         prior_ai_payoff_p = mean(scoring_rule(qp_r, outcome))) %>%
  mutate(baseline_action_p = ifelse(prior_human_payoff_p > prior_ai_payoff_p, qp_h, qp_r)) %>%
  mutate(baseline_p = scoring_rule(baseline_action_p, outcome)) %>%
  mutate(baseline2_action_p = ifelse(prior_human_payoff_p <= prior_ai_payoff_p, qp_h, qp_r)) %>%
  mutate(baseline2_p = scoring_rule(baseline2_action_p, outcome))
rational_data_p
```

```{r rational benchmark}
bin_size = 200
cut_breaks = seq(0, 1, length.out = bin_size + 1)
bin_middle = function(x) (2 * x - 1) / (2 * bin_size)
rational_actions = human_predictions %>%
  mutate(conf_bin = cut(qp_r, cut_breaks, include.lowest = TRUE)) %>%
  # group_by(qb_r, qb_h, conf_bin, order_question) %>%
  group_by(qb_r, qb_h, index) %>%
  mutate(pos_human_payoff = scoring_rule(qb_h, outcome),
         pos_ai_payoff = scoring_rule(qb_r, outcome)) %>%
  summarise(pos_human_payoff = mean(pos_human_payoff),
            pos_ai_payoff = mean(pos_ai_payoff))
rational_data = rational_data %>%
  mutate(conf_bin = cut(qp_r, cut_breaks, include.lowest = TRUE)) %>%
  left_join(rational_actions) %>%
  mutate(benchmark_action = ifelse(pos_human_payoff > pos_ai_payoff, qb_h, qb_r)) %>%
  mutate(benchmark = scoring_rule(benchmark_action, outcome))

rational_actions_p = human_predictions %>%
  mutate(qp_r_bin = cut(qp_r, cut_breaks, labels = FALSE, include.lowest = TRUE)) %>%
  mutate(qp_h_bin = cut(qp_h, cut_breaks, labels = FALSE, include.lowest = TRUE)) %>%
  group_by(qp_r_bin, qp_h_bin, index) %>%
  mutate(pos_human_payoff = scoring_rule(bin_middle(qp_h_bin), outcome),
         pos_ai_payoff = scoring_rule(bin_middle(qp_r_bin), outcome)) %>%
  summarise(pos_human_payoff = mean(pos_human_payoff),
            pos_ai_payoff = mean(pos_ai_payoff))
rational_data_p = rational_data_p %>%
  mutate(qp_r_bin = cut(qp_r, cut_breaks, labels = FALSE, include.lowest = TRUE)) %>%
  mutate(qp_h_bin = cut(qp_h, cut_breaks, labels = FALSE, include.lowest = TRUE)) %>%
  left_join(rational_actions_p) %>%
  mutate(benchmark_action_p = ifelse(pos_human_payoff > pos_ai_payoff, bin_middle(qp_h_bin), bin_middle(qp_r_bin))) %>%
  mutate(benchmark_p = scoring_rule(benchmark_action_p, outcome))
```

```{r calibrated human and AI}
bin_size = 5
cut_breaks = seq(0, 1, length.out = bin_size + 1)
bin_middle = function(x) (2 * x - 1) / (2 * bin_size)
smp_size <- floor(0.75 * nrow(human_predictions))

set.seed(123)
train_ind <- sample(seq_len(nrow(human_predictions)), size = smp_size)

train <- (human_predictions %>%
  mutate(qp_h_bin = cut(qp_h, cut_breaks, labels = FALSE, include.lowest = TRUE)) %>%
  mutate(qp_r_bin = cut(qp_r, cut_breaks, labels = FALSE, include.lowest = TRUE)))[train_ind, ]
test <- (human_predictions %>%
  mutate(qp_h_bin = cut(qp_h, cut_breaks, labels = FALSE, include.lowest = TRUE)) %>%
  mutate(qp_r_bin = cut(qp_r, cut_breaks, labels = FALSE, include.lowest = TRUE)))[-train_ind, ]

calibrated_human_actions = train %>%
  group_by(qp_h_bin) %>%
  summarise(calibrated_human_action = mean(outcome))

calibrated_AI_actions = train %>%
  group_by(qp_r_bin) %>%
  summarise(calibrated_ai_action = mean(outcome))

rational_calibrated_actions = train %>%
  group_by(qp_r_bin, qp_h_bin) %>%
  summarise(calibrated_rational_action = mean(outcome))

rational_prior_action = train %>%
  ungroup() %>%
  summarise(prior_rational_action = mean(outcome))

calibrated_data = test %>%
  left_join(calibrated_human_actions) %>%
  left_join(calibrated_AI_actions) %>%
  left_join(rational_calibrated_actions) %>%
  cross_join(rational_prior_action) %>%
  replace(is.na(.), as.numeric(rational_prior_action)) %>% 
  mutate(calibrated_human_payoff = scoring_rule(calibrated_human_action, outcome),
         calibrated_AI_payoff = scoring_rule(calibrated_ai_action, outcome),
         calibrated_rational_payoff = scoring_rule(calibrated_rational_action, outcome),
         prior_rational_payoff = scoring_rule(prior_rational_action, outcome),
         human_payoff = scoring_rule(qp_h, outcome),
         ai_payoff = scoring_rule(qp_r, outcome))

sample_size = 50
n_round = 500
calibrated_results = data.frame()
for (i in 1:n_round) {
  calibrated_results = calibrated_data %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    group_by(setting) %>%
    summarise(benchmark = mean(calibrated_rational_payoff), 
              baseline = mean(prior_rational_payoff),
              calibrated_human = mean(calibrated_human_payoff), 
              calibrated_ai = mean(calibrated_AI_payoff),
              human_payoff = mean(human_payoff),
              ai_payoff = mean(ai_payoff)) %>%
    rbind(calibrated_results)
}
calibrated_results

colors <- c("Benchmark" = "#1F2041", "calibrated_human" = "#fc8d62", "calibrated_ai" = "#8da0cb", "human" = "red", "Baseline" = "blue", "ai" = "green") 
ggplot() +
  stat_slabinterval(data = calibrated_results, aes(y = setting, x = calibrated_human, fill = "calibrated_human"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = calibrated_results, aes(y = setting, x = calibrated_ai, fill = "calibrated_ai"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = calibrated_results, aes(y = setting, x = benchmark, fill = "Benchmark"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = calibrated_results, aes(y = setting, x = human_payoff, fill = "human"), alpha = .8, color = "#202020", size = 3) +
  # stat_slabinterval(data = calibrated_results, aes(y = setting, x = ai_payoff, fill = "ai"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = calibrated_results, aes(y = setting, x = baseline, fill = "Baseline"), alpha = .8, color = "#202020", size = 3) +
  labs(x = "", y = "", color = "Quantiy") +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.major = element_line(colour = "grey"),
        axis.line.x = element_line(linewidth = 1.5, colour = "grey80"),
        panel.background = element_rect(fill = "white", color = "white"),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_line(colour = "grey")) + 
  scale_fill_manual(values = colors)
```

```{r bootstrap rational}
sample_size = 200
n_round = 500
rational_results = data.frame()
for (i in 1:n_round) {
  rational_results = rational_data %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    group_by(setting) %>%
    summarise(baseline = mean(baseline), 
              baseline2 = mean(baseline2), 
              benchmark = mean(benchmark)) %>%
    rbind(rational_results)
}
rational_results
```


```{r bootstrap rational p}
rational_results_p = data.frame()
for (i in 1:n_round) {
  rational_results_p = rational_data_p %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    group_by(setting) %>%
    summarise(baseline_p = mean(baseline_p), 
              baseline2_p = mean(baseline2_p), 
              benchmark_p = mean(benchmark_p)) %>%
    rbind(rational_results_p)
}
rational_results_p
```



```{r behavioral}
behavioral_data = exp_data %>%
  mutate(behavioral = scoring_rule(qb_hr, outcome))


behavioral_data_p = exp_data %>%
  mutate(behavioral_p = scoring_rule(qp_hr, outcome))
```

```{r bootstrap}
sample_size = 200
n_round = 500
behavioral_results = data.frame()
for (i in 1:n_round) {
  behavioral_result = behavioral_data %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    group_by(setting) %>%
    summarise(behavioral = mean(behavioral))
  reliance_level = behavioral_data %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    mutate(sample_id = row_number()) %>%
    group_by(setting, sample_id) %>%
    summarise(reliance_level = mean((qb_hr == qb_r) & !is.na(qb_h) & (qb_hr != qb_h))) %>%
    group_by(setting) %>%
    summarise(reliance_level = mean(reliance_level))
  misreliant = rational_data %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    left_join(reliance_level, by = c("setting")) %>%
    mutate(sample_id = row_number()) %>%
    group_by(sample_id, setting) %>%
    arrange(desc(pos_ai_payoff - pos_human_payoff), .by_group = TRUE) %>%
    mutate(sort_id = row_number()) %>%
    mutate(max_sort_id = max(sort_id)) %>%
    mutate(misreliant_action = ifelse(sort_id <= reliance_level * max_sort_id,
                                      qb_r, 
                                      qb_h)) %>%
    mutate(misreliant = scoring_rule(misreliant_action, outcome)) %>%
    group_by(setting) %>%
    summarise(misreliant = mean(misreliant))
  behavioral_results = behavioral_result %>%
    left_join(misreliant, by = c("setting")) %>%
    rbind(behavioral_results)
}
behavioral_results
```

```{r bootstrap p}
sample_size = 200
n_round = 500
behavioral_results_p = data.frame()
for (i in 1:n_round) {
  behavioral_result_p = behavioral_data_p %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    group_by(setting) %>%
    summarise(behavioral_p = mean(behavioral_p))
  reliance_level = behavioral_data_p %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    mutate(sample_id = row_number()) %>%
    group_by(setting, sample_id) %>%
    summarise(reliance_level = mean(((qp_hr - 0.5) * (qp_r - 0.5) > 0) & !is.na(qp_h) & (qp_hr - 0.5) * (qp_h - 0.5) < 0)) %>%
    group_by(setting) %>%
    summarise(reliance_level = mean(reliance_level))
  misreliant_p = rational_data_p %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    left_join(reliance_level, by = c("setting")) %>%
    mutate(sample_id = row_number()) %>%
    group_by(sample_id, setting) %>%
    arrange(desc(pos_ai_payoff - pos_human_payoff), .by_group = TRUE) %>%
    mutate(sort_id = row_number()) %>%
    mutate(max_sort_id = max(sort_id)) %>%
    mutate(misreliant_action = ifelse(sort_id <= reliance_level * max_sort_id,
                                      qp_r, 
                                      qp_h)) %>%
    mutate(misreliant_p = scoring_rule(misreliant_action, outcome)) %>%
    group_by(setting) %>%
    summarise(misreliant_p = mean(misreliant_p))
  behavioral_results_p = behavioral_result_p %>%
    left_join(misreliant_p, by = c("setting")) %>%
    rbind(behavioral_results_p)
}
behavioral_results_p
```


```{r visualization}
behavioral_results = behavioral_results %>% mutate(asking = "binary")
rational_results = rational_results %>% mutate(asking = "binary")

behavioral_results_p = behavioral_results_p %>% mutate(asking = "probability")
rational_results_p = rational_results_p %>% mutate(asking = "probability")

colors <- c("Baseline" = "#a6d854", "Baseline(human alone)" = "#e78ac3", "Benchmark" = "#1F2041", "Behavioral" = "#fc8d62", "Misreliant" = "#8da0cb")
ggplot() +
  stat_slabinterval(data = behavioral_results, aes(y = setting, x = behavioral, fill = "Behavioral"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = behavioral_results, aes(y = setting, x = misreliant, fill = "Misreliant"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results, aes(y = setting, x = baseline, fill = "Baseline"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results, aes(y = setting, x = baseline2, fill = "Baseline(human alone)"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results, aes(y = setting, x = benchmark, fill = "Benchmark"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = behavioral_results_p, aes(y = setting, x = behavioral_p, fill = "Behavioral"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = behavioral_results_p, aes(y = setting, x = misreliant_p, fill = "Misreliant"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results_p, aes(y = setting, x = baseline_p, fill = "Baseline"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results_p, aes(y = setting, x = baseline2_p, fill = "Baseline(human alone)"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results_p, aes(y = setting, x = benchmark_p, fill = "Benchmark"), alpha = .8, color = "#202020", size = 3) +
  labs(x = "", y = "", color = "Quantiy") +
  facet_grid(rows = vars(asking)) +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.major = element_line(colour = "grey"),
        axis.line.x = element_line(linewidth = 1.5, colour = "grey80"),
        panel.background = element_rect(fill = "white", color = "white"),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_line(colour = "grey")) + 
  scale_fill_manual(values = colors)
ggsave("./fogliato_results_poster.pdf", unit = "in", width = 7.22222222222 * 1.2, height = 3.47222222222)
```

```{r reliance plot}
quantile_data = rational_data %>%
  group_by(index) %>%
  summarise(EAIhuman = mean(pos_ai_payoff - pos_human_payoff)) %>%
  arrange(desc(EAIhuman)) %>%
  mutate(sortId = row_number())
quantile_data = quantile_data %>%
  mutate(quantile = sortId / nrow(quantile_data)) %>%
  mutate(group_row = "Quantile") %>%
  mutate(cum_EAIhuman = cumsum(EAIhuman))
reliance_data = behavioral_data %>% 
  group_by(order_question, setting) %>% 
  mutate(p_id = row_number()) %>%
  group_by(setting, p_id) %>%
  summarise(reliance = mean((qb_hr == qb_r) & !is.na(qb_h) & (qb_hr != qb_h)))

quantile_data_p = rational_data_p %>%
  group_by(index) %>%
  summarise(EAIhuman = mean(pos_ai_payoff - pos_human_payoff)) %>%
  arrange(desc(EAIhuman)) %>%
  mutate(sortId = row_number())
quantile_data_p = quantile_data_p %>%
  mutate(quantile = sortId / nrow(quantile_data)) %>%
  mutate(group_row = "Quantile") %>%
  mutate(cum_EAIhuman = cumsum(EAIhuman))
reliance_data_p = behavioral_data_p %>% 
  group_by(order_question, setting) %>% 
  mutate(p_id = row_number()) %>%
  group_by(setting, p_id) %>%
  summarise(reliance = mean(((qp_hr - 0.5) * (qp_r - 0.5) > 0) & !is.na(qp_h) & (qp_hr - 0.5) * (qp_h - 0.5) < 0))


p11 = quantile_data %>%
  ggplot() +
  geom_line(aes(x = quantile, y = EAIhuman)) +
  geom_hline(yintercept = 0) +
  labs(x = "The Quantile of Signals", y = "", color = '') +
  xlim(0, 1) +
  ylim(-1, 1)+
  theme_light()
p21 = reliance_data %>%
  ggplot() +
  stat_pointinterval(aes(x = reliance, y = setting, color = setting), point_size = 2) +
  xlim(0, 1) +
  theme_light() +
  theme(legend.position = "none") +
  scale_y_discrete(labels = c(-0.5,0.0)) +
  labs(x = "Reliance Levels", y = "", color = '')

p12 = quantile_data_p %>%
  ggplot() +
  geom_line(aes(x = quantile, y = EAIhuman)) +
  geom_hline(yintercept = 0) +
  labs(x = "The Quantile of Signals", y = "", color = '') +
  xlim(0, 1) +
  ylim(-1, 1)+
  theme_light()
p22 = reliance_data_p %>%
  ggplot() +
  stat_pointinterval(aes(x = reliance, y = setting, color = setting), point_size = 2) +
  xlim(0, 1) +
  theme_light() +
  theme(legend.position = "none") +
  scale_y_discrete(labels = c(-0.5,0.0)) +
  labs(x = "Reliance Levels", y = "", color = '')
plot_grid(p11, p12, p21, p22, cols = 2)
ggsave("./fogliato_reliance.pdf", unit = "in", width = 7.22222222222 * 0.9, height = 3.47222222222 * 1.2)
```

```{r reliance plot}
rational_data %>%
  group_by(index) %>%
  summarise(EAIhuman = mean(pos_ai_payoff - pos_human_payoff)) %>%
  arrange(EAIhuman) %>%
  mutate(sortId = row_number()) %>%
  ggplot() +
  geom_line(aes(x = sortId, y = EAIhuman)) +
  geom_hline(yintercept = 0) +
  stat_pointinterval(data = behavioral_data %>% 
                       group_by(order_question, setting) %>% 
                       mutate(p_id = row_number()) %>%
                       group_by(setting, p_id) %>%
                       summarise(reliance = mean((qb_hr == qb_r) & !is.na(qb_h) & (qb_hr != qb_h))), 
                     mapping = aes(x = 3117 * (1 - reliance), y = 0, color = setting),
                     position = "dodge") +
  labs(x = "Sorted signals", y = "E[AI - human]", color = '') +
  theme_bw()
ggsave("./fogliato_reliance.pdf", unit = "in", width = 7.22222222222, height = 3.47222222222)
```

```{r reliance plot}
rational_data_p %>%
  group_by(index) %>%
  summarise(EAIhuman = mean(pos_ai_payoff - pos_human_payoff)) %>%
  arrange(EAIhuman) %>%
  mutate(sortId = row_number()) %>%
  ggplot() +
  geom_line(aes(x = sortId, y = EAIhuman)) +
  geom_hline(yintercept = 0) +
  stat_pointinterval(data = behavioral_data_p %>% 
                       group_by(order_question, setting) %>% 
                       mutate(p_id = row_number()) %>%
                       group_by(setting, p_id) %>%
                       summarise(reliance = mean(((qp_hr - 0.5) * (qp_r - 0.5) > 0) & !is.na(qp_h) & (qp_hr - 0.5) * (qp_h - 0.5) < 0)), 
                     mapping = aes(x = 3117 * (1 - reliance), y = 0, color = setting)) +
  labs(x = "Sorted signals", y = "E[AI - human]") +
  theme_bw()
```


# Using discretized signals to approximate

```{r discretized signals}
rational_data = human_predictions %>% 
  mutate(prior_human_payoff = mean(scoring_rule(qb_h, outcome)),
         prior_ai_payoff = mean(scoring_rule(qb_r, outcome))) %>%
  mutate(baseline_action = ifelse(prior_human_payoff > prior_ai_payoff, qb_h, qb_r)) %>%
  mutate(baseline = scoring_rule(baseline_action, outcome)) %>%
  mutate(baseline2_action = ifelse(prior_human_payoff <= prior_ai_payoff, qb_h, qb_r)) %>%
  mutate(baseline2 = scoring_rule(baseline2_action, outcome))

rational_data_p = human_predictions %>% 
  mutate(prior_human_payoff_p = mean(scoring_rule(qp_h, outcome)),
         prior_ai_payoff_p = mean(scoring_rule(qp_r, outcome))) %>%
  mutate(baseline_action_p = ifelse(prior_human_payoff_p > prior_ai_payoff_p, qp_h, qp_r)) %>%
  mutate(baseline_p = scoring_rule(baseline_action_p, outcome)) %>%
  mutate(baseline2_action_p = ifelse(prior_human_payoff_p <= prior_ai_payoff_p, qp_h, qp_r)) %>%
  mutate(baseline2_p = scoring_rule(baseline2_action_p, outcome))


bin_size = 200
cut_breaks = seq(0, 1, length.out = bin_size + 1)
bin_middle = function(x) (2 * x - 1) / (2 * bin_size)
rational_actions = human_predictions %>%
  mutate(conf_bin = cut(qp_r, cut_breaks, include.lowest = TRUE)) %>%
  group_by(qb_r, qb_h, conf_bin) %>%
  mutate(pos_human_payoff = scoring_rule(qb_h, outcome),
         pos_ai_payoff = scoring_rule(qb_r, outcome)) %>%
  summarise(pos_human_payoff = mean(pos_human_payoff),
            pos_ai_payoff = mean(pos_ai_payoff))
rational_data = rational_data %>%
  mutate(conf_bin = cut(qp_r, cut_breaks, include.lowest = TRUE)) %>%
  left_join(rational_actions) %>%
  mutate(benchmark_action = ifelse(pos_human_payoff > pos_ai_payoff, qb_h, qb_r)) %>%
  mutate(benchmark = scoring_rule(benchmark_action, outcome))

rational_actions_p = human_predictions %>%
  mutate(qp_r_bin = cut(qp_r, cut_breaks, labels = FALSE, include.lowest = TRUE)) %>%
  mutate(qp_h_bin = cut(qp_h, cut_breaks, labels = FALSE, include.lowest = TRUE)) %>%
  group_by(qp_r_bin, qp_h_bin) %>%
  mutate(pos_human_payoff = scoring_rule(bin_middle(qp_h_bin), outcome),
         pos_ai_payoff = scoring_rule(bin_middle(qp_r_bin), outcome)) %>%
  summarise(pos_human_payoff = mean(pos_human_payoff),
            pos_ai_payoff = mean(pos_ai_payoff))
rational_data_p = rational_data_p %>%
  mutate(qp_r_bin = cut(qp_r, cut_breaks, labels = FALSE, include.lowest = TRUE)) %>%
  mutate(qp_h_bin = cut(qp_h, cut_breaks, labels = FALSE, include.lowest = TRUE)) %>%
  left_join(rational_actions_p) %>%
  mutate(benchmark_action_p = ifelse(pos_human_payoff > pos_ai_payoff, bin_middle(qp_h_bin), bin_middle(qp_r_bin))) %>%
  mutate(benchmark_p = scoring_rule(benchmark_action_p, outcome))

sample_size = 200
n_round = 500
rational_results = data.frame()
for (i in 1:n_round) {
  rational_results = rational_data %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    group_by(setting) %>%
    summarise(baseline = mean(baseline), 
              baseline2 = mean(baseline2), 
              benchmark = mean(benchmark)) %>%
    rbind(rational_results)
}

rational_results_p = data.frame()
for (i in 1:n_round) {
  rational_results_p = rational_data_p %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    group_by(setting) %>%
    summarise(baseline_p = mean(baseline_p), 
              baseline2_p = mean(baseline2_p), 
              benchmark_p = mean(benchmark_p)) %>%
    rbind(rational_results_p)
}

behavioral_data = exp_data %>%
  mutate(behavioral = scoring_rule(qb_hr, outcome))


behavioral_data_p = exp_data %>%
  mutate(behavioral_p = scoring_rule(qp_hr, outcome))

behavioral_results = data.frame()
for (i in 1:n_round) {
  behavioral_result = behavioral_data %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    group_by(setting) %>%
    summarise(behavioral = mean(behavioral))
  reliance_level = behavioral_data %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    mutate(sample_id = row_number()) %>%
    group_by(setting, sample_id) %>%
    summarise(reliance_level = mean((qb_hr == qb_r) & !is.na(qb_h) & (qb_hr != qb_h))) %>%
    group_by(setting) %>%
    summarise(reliance_level = mean(reliance_level))
  misreliant = rational_data %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    left_join(reliance_level, by = c("setting")) %>%
    mutate(sample_id = row_number()) %>%
    group_by(sample_id, setting) %>%
    arrange(desc(pos_ai_payoff - pos_human_payoff), .by_group = TRUE) %>%
    mutate(sort_id = row_number()) %>%
    mutate(max_sort_id = max(sort_id)) %>%
    mutate(misreliant_action = ifelse(sort_id <= reliance_level * max_sort_id,
                                      qb_r, 
                                      qb_h)) %>%
    mutate(misreliant = scoring_rule(misreliant_action, outcome)) %>%
    group_by(setting) %>%
    summarise(misreliant = mean(misreliant))
  behavioral_results = behavioral_result %>%
    left_join(misreliant, by = c("setting")) %>%
    rbind(behavioral_results)
}

behavioral_results_p = data.frame()
for (i in 1:n_round) {
  behavioral_result_p = behavioral_data_p %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    group_by(setting) %>%
    summarise(behavioral_p = mean(behavioral_p))
  reliance_level = behavioral_data_p %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    mutate(sample_id = row_number()) %>%
    group_by(setting, sample_id) %>%
    summarise(reliance_level = mean(((qp_hr - 0.5) * (qp_r - 0.5) > 0) & !is.na(qp_h) & (qp_hr - 0.5) * (qp_h - 0.5) < 0)) %>%
    group_by(setting) %>%
    summarise(reliance_level = mean(reliance_level))
  misreliant_p = rational_data_p %>% 
    group_by(order_question, setting) %>%
    sample_n(sample_size) %>%
    left_join(reliance_level, by = c("setting")) %>%
    mutate(sample_id = row_number()) %>%
    group_by(sample_id, setting) %>%
    arrange(desc(pos_ai_payoff - pos_human_payoff), .by_group = TRUE) %>%
    mutate(sort_id = row_number()) %>%
    mutate(max_sort_id = max(sort_id)) %>%
    mutate(misreliant_action = ifelse(sort_id <= reliance_level * max_sort_id,
                                      qp_r, 
                                      qp_h)) %>%
    mutate(misreliant_p = scoring_rule(misreliant_action, outcome)) %>%
    group_by(setting) %>%
    summarise(misreliant_p = mean(misreliant_p))
  behavioral_results_p = behavioral_result_p %>%
    left_join(misreliant_p, by = c("setting")) %>%
    rbind(behavioral_results_p)
}


behavioral_results = behavioral_results %>% mutate(asking = "binary")
rational_results = rational_results %>% mutate(asking = "binary")

behavioral_results_p = behavioral_results_p %>% mutate(asking = "probability")
rational_results_p = rational_results_p %>% mutate(asking = "probability")

colors <- c("Baseline" = "#a6d854", "Baseline(human alone)" = "#e78ac3", "Benchmark" = "#1F2041", "Behavioral" = "#fc8d62", "Misreliant" = "#8da0cb")
ggplot() +
  stat_slabinterval(data = behavioral_results, aes(y = setting, x = behavioral, fill = "Behavioral"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = behavioral_results, aes(y = setting, x = misreliant, fill = "Misreliant"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results, aes(y = setting, x = baseline, fill = "Baseline"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results, aes(y = setting, x = baseline2, fill = "Baseline(human alone)"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results, aes(y = setting, x = benchmark, fill = "Benchmark"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = behavioral_results_p, aes(y = setting, x = behavioral_p, fill = "Behavioral"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = behavioral_results_p, aes(y = setting, x = misreliant_p, fill = "Misreliant"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results_p, aes(y = setting, x = baseline_p, fill = "Baseline"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results_p, aes(y = setting, x = baseline2_p, fill = "Baseline(human alone)"), alpha = .8, color = "#202020", size = 3) +
  stat_slabinterval(data = rational_results_p, aes(y = setting, x = benchmark_p, fill = "Benchmark"), alpha = .8, color = "#202020", size = 3) +
  labs(x = "", y = "", color = "Quantiy") +
  facet_grid(rows = vars(asking)) +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.major = element_line(colour = "grey"),
        axis.line.x = element_line(linewidth = 1.5, colour = "grey80"),
        panel.background = element_rect(fill = "white", color = "white"),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_line(colour = "grey")) + 
  scale_fill_manual(values = colors)
# ggsave("./fogliato_results_test_performance.pdf", unit = "in", width = 7.22222222222, height = 3.47222222222)
```



